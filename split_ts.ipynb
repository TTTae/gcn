{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        user_id  product_id  category_id  rating  helpfulness            ts\n0        9427.0     30901.0         15.0     5.0          1.0  9.311580e+08\n1       18547.0     59917.0         15.0     4.0          2.0  9.312444e+08\n2       17852.0    104419.0          9.0     5.0          1.0  9.313308e+08\n3        9988.0     28323.0          7.0     5.0          2.0  9.314172e+08\n4        9988.0     30419.0          3.0     2.0          2.0  9.314172e+08\n...         ...         ...          ...     ...          ...           ...\n922262  12343.0    218980.0         18.0     1.0          2.0  1.304838e+09\n922263  19912.0    300021.0         17.0     5.0          2.0  1.304924e+09\n922264  18283.0    125068.0          3.0     3.0          2.0  1.304924e+09\n922265   6979.0     69081.0          9.0     5.0          2.0  1.304924e+09\n922266    294.0     30668.0          8.0     3.0          2.0  1.304924e+09\n\n[922267 rows x 6 columns]\ndict_keys([931158000.0, 968569200.0, 1005980400.0, 1043391600.0, 1080802800.0, 1118214000.0, 1155625200.0, 1193036400.0, 1230447600.0, 1267858800.0])\n"
     ]
    }
   ],
   "source": [
    "### split data into train data and test data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "my_data = np.loadtxt(\"my_data.txt\")\n",
    "\n",
    "my_data = pd.DataFrame(my_data)\n",
    "my_data.columns = [\"user_id\", \"product_id\", \"category_id\", \"rating\", \"helpfulness\", \"ts\"]\n",
    "my_data.sort_values(\"ts\", ascending=True, inplace=True)\n",
    "my_data.reset_index(drop=True, inplace=True)\n",
    "print(my_data)\n",
    "\n",
    "filename = 'dim1_dict'\n",
    "infile = open(filename,'rb')\n",
    "my_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "print(my_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "37376640\n"
     ]
    }
   ],
   "source": [
    "time_span = int((my_data[\"ts\"].max() - my_data[\"ts\"].min())/10)\n",
    "print(time_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "One ts finished\n",
      "--------\n",
      "Start time:  968569200.0 End time:  1005945840.0\n",
      "300000\n",
      "350000\n",
      "400000\n",
      "450000\n",
      "One ts finished\n",
      "--------\n",
      "Start time:  1005980400.0 End time:  1043357040.0\n",
      "500000\n",
      "One ts finished\n",
      "--------\n",
      "Start time:  1043391600.0 End time:  1080768240.0\n",
      "550000\n",
      "One ts finished\n",
      "--------\n",
      "Start time:  1080802800.0 End time:  1118179440.0\n",
      "600000\n",
      "650000\n",
      "One ts finished\n",
      "--------\n",
      "Start time:  1118214000.0 End time:  1155590640.0\n",
      "700000\n",
      "One ts finished\n",
      "--------\n",
      "Start time:  1155625200.0 End time:  1193001840.0\n",
      "750000\n",
      "One ts finished\n",
      "--------\n",
      "Start time:  1193036400.0 End time:  1230413040.0\n",
      "800000\n",
      "One ts finished\n",
      "--------\n",
      "Start time:  1230447600.0 End time:  1267824240.0\n",
      "850000\n",
      "Adding test set\n",
      "One ts finished\n",
      "--------\n",
      "Start time:  1267858800.0 End time:  1305235440.0\n",
      "900000\n",
      "All finished\n"
     ]
    }
   ],
   "source": [
    "start_time = my_data.iloc[0,5]\n",
    "end_time = start_time + time_span\n",
    "\n",
    "item_list = []\n",
    "user_list = []\n",
    "ts_list = []\n",
    "ts_interaction_dict = {}\n",
    "ts_interaction_dict_test = {}\n",
    "\n",
    "for idx, row in my_data.iterrows():\n",
    "    \n",
    "    item_id = row[\"product_id\"]\n",
    "    user_id = row[\"user_id\"]\n",
    "    current_time = row[\"ts\"]\n",
    "    \n",
    "    if idx % 50000 == 0:\n",
    "        print(idx)\n",
    "    if current_time > end_time:\n",
    "        user_list = np.array(user_list)\n",
    "        item_list = np.array(item_list)\n",
    "        ts_list = np.array(ts_list)\n",
    "        \n",
    "        if len(ts_interaction_dict) >= 8:\n",
    "            print(\"Adding test set\")\n",
    "            ts_interaction_dict_test[start_time] = np.hstack((user_list, item_list, ts_list))  \n",
    "\n",
    "\n",
    "        else:\n",
    "            \n",
    "            ts_interaction_dict[start_time] = np.hstack((user_list, item_list, ts_list))  \n",
    "            \n",
    "\n",
    "\n",
    "        start_time = current_time\n",
    "        end_time = start_time + time_span\n",
    "        print(\"One ts finished\")\n",
    "        \n",
    "        \n",
    "        print(\"--------\")\n",
    "        ### reinitialize co_review dict for next time\n",
    "        print(\"Start time: \", start_time, \"End time: \", end_time)\n",
    "        item_list = []\n",
    "        user_list = []\n",
    "        ts_list = []\n",
    "        \n",
    "    user_list.append([user_id])\n",
    "    item_list.append([item_id])\n",
    "    ts_list.append([current_time])\n",
    "\n",
    "# ts_interaction_dict[start_time] = np.concatenate((user_list, item_list, ts_list), axis=1)\n",
    "ts_interaction_dict_test[start_time] = np.hstack((user_list, item_list, ts_list)) \n",
    "print(\"All finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8\n2\n"
     ]
    }
   ],
   "source": [
    "print(len(ts_interaction_dict))\n",
    "print(len(ts_interaction_dict_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'ts_interaction_dict.pkl'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(ts_interaction_dict,outfile)\n",
    "outfile.close()\n",
    "\n",
    "filename = 'ts_interaction_dict_test.pkl'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(ts_interaction_dict_test,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'dict'>\n8\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'ts_interaction_dict.pkl'\n",
    "infile = open(filename,'rb')\n",
    "new_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "\n",
    "print(type(new_dict))\n",
    "print(len(new_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'dict'>\n2\n"
     ]
    }
   ],
   "source": [
    "filename = 'ts_interaction_dict_test.pkl'\n",
    "infile = open(filename,'rb')\n",
    "new_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "\n",
    "print(type(new_dict))\n",
    "print(len(new_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}